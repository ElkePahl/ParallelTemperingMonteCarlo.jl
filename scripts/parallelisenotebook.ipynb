{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition (::Type{ParallelTemperingMonteCarlo.EnergyEvaluation.AbstractMLPotential})(String, String) in module EnergyEvaluation at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/src/EnergyEvaluation.jl:43 overwritten at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/src/EnergyEvaluation.jl:48.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LoadError: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ArgumentError: Package ParallelTemperingMonteCarlo does not have Threads in its dependencies:\n",
      "- If you have ParallelTemperingMonteCarlo checked out for development and have\n",
      "  added Threads as a dependency but haven't updated your primary\n",
      "  environment's manifest file, try `Pkg.resolve()`.\n",
      "- Otherwise you may need to report an issue with ParallelTemperingMonteCarlo\n",
      "Stacktrace:\n",
      "  [1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m\u001b[4mloading.jl:980\u001b[24m\u001b[39m\n",
      "  [2] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90m_path\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mBase.jl:418\u001b[24m\u001b[39m\n",
      "  [3] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[35mParallelTemperingMonteCarlo\u001b[39m \u001b[90m~/Code/ParallelTemperingMonteCarlo.jl/src/\u001b[39m\u001b[90m\u001b[4mParallelTemperingMonteCarlo.jl:1\u001b[24m\u001b[39m\n",
      "  [4] top-level scope\n",
      "\u001b[90m    @ \u001b[39m\u001b[90m~/Code/ParallelTemperingMonteCarlo.jl/src/\u001b[39m\u001b[90m\u001b[4mParallelTemperingMonteCarlo.jl:14\u001b[24m\u001b[39m\n",
      "  [5] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mBase.jl:418\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [6] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt64}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mloading.jl:1318\u001b[24m\u001b[39m\n",
      "  [7] top-level scope\n",
      "\u001b[90m    @ \u001b[39m\u001b[90m\u001b[4mnone:1\u001b[24m\u001b[39m\n",
      "  [8] \u001b[0m\u001b[1meval\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:373\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [9] \u001b[0m\u001b[1meval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mExpr\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[90mBase.MainInclude\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mclient.jl:453\u001b[24m\u001b[39m\n",
      " [10] top-level scope\n",
      "\u001b[90m    @ \u001b[39m\u001b[90m\u001b[4mnone:1\u001b[24m\u001b[39m\n",
      "in expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/src/ParallelRun.jl:1\n",
      "in expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/src/ParallelTemperingMonteCarlo.jl:1\n"
     ]
    },
    {
     "ename": "ErrorException",
     "evalue": "Failed to precompile ParallelTemperingMonteCarlo [3b4a078d-6172-48b3-819b-6f35da58c07f] to /home/grayseff/.julia/compiled/v1.7/ParallelTemperingMonteCarlo/jl_CUrLjA.",
     "output_type": "error",
     "traceback": [
      "Failed to precompile ParallelTemperingMonteCarlo [3b4a078d-6172-48b3-819b-6f35da58c07f] to /home/grayseff/.julia/compiled/v1.7/ParallelTemperingMonteCarlo/jl_CUrLjA.\n",
      "\n",
      "Stacktrace:\n",
      " [1] error(s::String)\n",
      "   @ Base ./error.jl:33\n",
      " [2] compilecache(pkg::Base.PkgId, path::String, internal_stderr::IO, internal_stdout::IO, ignore_loaded_modules::Bool)\n",
      "   @ Base ./loading.jl:1466\n",
      " [3] compilecache(pkg::Base.PkgId, path::String)\n",
      "   @ Base ./loading.jl:1410\n",
      " [4] _require(pkg::Base.PkgId)\n",
      "   @ Base ./loading.jl:1120\n",
      " [5] require(uuidkey::Base.PkgId)\n",
      "   @ Base ./loading.jl:1013\n",
      " [6] require(into::Module, mod::Symbol)\n",
      "   @ Base ./loading.jl:997\n",
      " [7] top-level scope\n",
      "   @ /opt/julias/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/macros.jl:200"
     ]
    }
   ],
   "source": [
    "using Distributed\n",
    "using Base.Threads\n",
    "\n",
    "\n",
    "@everywhere begin\n",
    "    using BenchmarkTools\n",
    "    using ParallelTemperingMonteCarlo\n",
    "end\n",
    "addprocs(nthreads())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use a function of several variables in the pmap environment we require a curry function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere curry(f,y) = x -> f(x,y)\n",
    "@everywhere add_xy(x,y) = x + y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Int64}:\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pmap(curry(add_xy,10), 1:5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB spawning processes is expensive and _not recommended at all_ for simple loops and functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync macros\n",
    "\n",
    "sync requires all tasks inside to complete before moving on, async moves right on along without waiting, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slept for two\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nice and rested\n"
     ]
    }
   ],
   "source": [
    "@sync begin\n",
    "    sleep(2)\n",
    "    println(\"slept for two\")\n",
    "\n",
    "    @async begin \n",
    "        sleep(5)\n",
    "        println(\"nice and rested\")\n",
    "    end\n",
    "#the async wrapper skips straight to done\n",
    "    println(\"done\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll simulate a complex process with a 2 second sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simtest (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function simtest(x)\n",
    "    sleep(2)\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      " 20.244031 seconds (307.77 k allocations: 16.546 MiB, 1.10% compilation time)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  2.014825 seconds (2.56 k allocations: 129.622 KiB, 0.70% compilation time)\n"
     ]
    }
   ],
   "source": [
    "@time begin \n",
    "    veccy = []\n",
    "    for i = 1:10\n",
    "\n",
    "        y = simtest(i)\n",
    "        push!(veccy,y)\n",
    "        \n",
    "    end\n",
    "    println(veccy)\n",
    "end\n",
    "\n",
    "@time begin \n",
    "    @sync for i = 1:10\n",
    "        veccy = []\n",
    "        @async begin \n",
    "            y = simtest(i)\n",
    "            push!(veccy,y)\n",
    "        end\n",
    "    end\n",
    "    println(veccy)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Asynchronous tasks are not parallel, demonstrated above they do boost performance for large operations. Use @spawn not @async for parallel operations\n",
    "\n",
    "Let's test a data unsafe operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: both Threads and Distributed export \"@spawn\"; uses of it in module Main must be qualified\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @spawn not defined\nin expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:5",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @spawn not defined\n",
      "in expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:5\n"
     ]
    }
   ],
   "source": [
    "function printtest(x::Bool = true)\n",
    "    println(\"begin\")\n",
    "    if x == true\n",
    "        @sync for i=1:10\n",
    "            @spawn println(\"$i $i $i $i $i \")\n",
    "        end\n",
    "    else\n",
    "        for i=1:10\n",
    "            println(\"$i $i $i $i $i \")\n",
    "        end\n",
    "    end\n",
    "    println(\"end\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: printtest not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: printtest not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ./timing.jl:220 [inlined]\n",
      " [2] top-level scope\n",
      "   @ ~/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:0"
     ]
    }
   ],
   "source": [
    "@time printtest()\n",
    "println(\"done\")\n",
    "\n",
    "@time printtest(false)\n",
    "println(\"done\")\n",
    "# @time begin \n",
    "#     println(\"begin\")\n",
    "#     @threads for i=1:10\n",
    "#         println(\"$i $i $i $i $i \")\n",
    "#     end\n",
    "#     println(\"end\")\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB \n",
    "Categorically do not use @spawn where data ordering is relevant. Additionally, it is considered bad practice to parallelise any operation faster than 100 $\\mu m$ for threads or 100ms for spawning as it does not increase speed enough to compensate for the time taken to spawn the operation.\n",
    "\n",
    "Below we test specific functions for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onwards, time-testing some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: TempGrid not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: TempGrid not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:8"
     ]
    }
   ],
   "source": [
    "n_atoms = 13\n",
    "\n",
    "# temperature grid\n",
    "ti = 5.\n",
    "tf = 16.\n",
    "n_traj = 32\n",
    "\n",
    "temp = TempGrid{n_traj}(ti,tf) \n",
    "\n",
    "# MC simulation details\n",
    "mc_cycles = 300000 #default 20% equilibration cycles on top\n",
    "mc_sample = 1  #sample every mc_sample MC cycles\n",
    "\n",
    "#move_atom=AtomMove(n_atoms) #move strategy (here only atom moves, n_atoms per MC cycle)\n",
    "displ_atom = 0.1 # Angstrom\n",
    "n_adjust = 100\n",
    "\n",
    "max_displ_atom = [0.1*sqrt(displ_atom*temp.t_grid[i]) for i in 1:n_traj]\n",
    "\n",
    "mc_params = MCParams(mc_cycles, n_traj, n_atoms, mc_sample = mc_sample, n_adjust = n_adjust)\n",
    "\n",
    "#moves - allowed at present: atom, volume and rotation moves (volume,rotation not yet implemented)\n",
    "move_strat = MoveStrategy(atom_moves = n_atoms)  \n",
    "\n",
    "#ensemble\n",
    "ensemble = NVT(n_atoms)\n",
    "\n",
    "#ELJpotential for neon\n",
    "#c1=[-10.5097942564988, 0., 989.725135614556, 0., -101383.865938807, 0., 3918846.12841668, 0., -56234083.4334278, 0., 288738837.441765]\n",
    "#elj_ne1 = ELJPotential{11}(c1)\n",
    "\n",
    "c=[-10.5097942564988, 989.725135614556, -101383.865938807, 3918846.12841668, -56234083.4334278, 288738837.441765]\n",
    "pot = ELJPotentialEven{6}(c)\n",
    "\n",
    "#starting configurations\n",
    "#icosahedral ground state of Ne13 (from Cambridge cluster database) in Angstrom\n",
    "pos_ne13 = [[2.825384495892464, 0.928562467914040, 0.505520149314310],\n",
    "[2.023342172678102,\t-2.136126268595355, 0.666071287554958],\n",
    "[2.033761811732818,\t-0.643989413759464, -2.133000349161121],\n",
    "[0.979777205108572,\t2.312002562803556, -1.671909307631893],\n",
    "[0.962914279874254,\t-0.102326586625353, 2.857083360096907],\n",
    "[0.317957619634043,\t2.646768968413408, 1.412132053672896],\n",
    "[-2.825388342924982, -0.928563755928189, -0.505520471387560],\n",
    "[-0.317955944853142, -2.646769840660271, -1.412131825293682],\n",
    "[-0.979776174195320, -2.312003751825495, 1.671909138648006],\n",
    "[-0.962916072888105, 0.102326392265998,\t-2.857083272537599],\n",
    "[-2.023340541398004, 2.136128558801072,\t-0.666071089291685],\n",
    "[-2.033762834001679, 0.643989905095452, 2.132999911364582],\n",
    "[0.000002325340981,\t0.000000762100600, 0.000000414930733]]\n",
    "\n",
    "#convert to Bohr\n",
    "AtoBohr = 1.8897259886\n",
    "pos_ne13 = pos_ne13 * AtoBohr\n",
    "\n",
    "length(pos_ne13) == n_atoms || error(\"number of atoms and positions not the same - check starting config\")\n",
    "\n",
    "#boundary conditions \n",
    "bc_ne13 = SphericalBC(radius=5.32*AtoBohr)   #5.32 Angstrom\n",
    "\n",
    "#starting configuration\n",
    "start_config = Config(pos_ne13, bc_ne13)\n",
    "\n",
    "#histogram information\n",
    "n_bin = 100\n",
    "#en_min = -0.006    #might want to update after equilibration run if generated on the fly\n",
    "#en_max = -0.001    #otherwise will be determined after run as min/max of sampled energies (ham vector)\n",
    "\n",
    "#construct array of MCState (for each temperature)\n",
    "mc_states = [MCState(temp.t_grid[i], temp.beta_grid[i], start_config, pot; max_displ=[max_displ_atom[i],0.01,1.]) for i in 1:n_traj]\n",
    "\n",
    "#results = Output(n_bin, max_displ_vec)\n",
    "results = Output{Float64}(n_bin; en_min = mc_states[1].en_tot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above we just define the 13 atom system, below we show that threading halves the time taken to complete one mc_step per trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @benchmark not defined\nin expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @benchmark not defined\n",
      "in expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1\n"
     ]
    }
   ],
   "source": [
    "@benchmark begin \n",
    "    for i in 1:mc_params.n_traj\n",
    "        mc_step!(mc_states[i],pot,ensemble,1,0,0);\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @benchmark not defined\nin expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @benchmark not defined\n",
      "in expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1\n"
     ]
    }
   ],
   "source": [
    "@benchmark begin \n",
    "    @threads for i in 1:mc_params.n_traj\n",
    "        mc_step!(mc_states[i],pot,ensemble,1,0,0);\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @benchmark not defined\nin expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @benchmark not defined\n",
      "in expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1\n"
     ]
    }
   ],
   "source": [
    "@benchmark begin \n",
    "    for i in 1:mc_params.n_traj\n",
    "        x = MCRun.atom_displacement(mc_states[i].config.pos[2],mc_states[i].max_displ[1],mc_states[i].config.bc);\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @benchmark not defined\nin expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @benchmark not defined\n",
      "in expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1\n"
     ]
    }
   ],
   "source": [
    "@benchmark begin \n",
    "    @threads for i in 1:mc_params.n_traj\n",
    "        x = MCRun.atom_displacement(mc_states[i].config.pos[2],mc_states[i].max_displ[1],mc_states[i].config.bc);\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a speed-up in calculation for the atom_displacement step, but the greatest increase is to complete the metropolis condition as well, so threading works perfectly for the dimer by simply threading the loops. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to test the writing step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test printing 32 (traj) iterations of 55(atoms) and time this with the @sync @sync vs without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @benchmark not defined\nin expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @benchmark not defined\n",
      "in expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1\n"
     ]
    }
   ],
   "source": [
    "t1 = @benchmark begin\n",
    "    filetest = open(\"test.dat\", \"w+\")\n",
    "    \n",
    "    @sync begin\n",
    "    @async for i=1:32\n",
    "         @async for j=1:55\n",
    "            write(filetest,\"$i $j \\n\")\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "close(filetest)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @benchmark not defined\nin expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @benchmark not defined\n",
      "in expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1\n"
     ]
    }
   ],
   "source": [
    "t2 = @benchmark begin\n",
    "    filetest = open(\"test2.dat\", \"w+\")\n",
    "    \n",
    "    begin\n",
    "    for i=1:32\n",
    "        for j=1:55\n",
    "            write(filetest,\"$i $j \\n\")\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "    close(filetest)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's slower to use the sync async functionality, but the atom-invariance within trajectories may make @spawn or @threads more useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @benchmark not defined\nin expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @benchmark not defined\n",
      "in expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1\n"
     ]
    }
   ],
   "source": [
    "t3 = @benchmark begin\n",
    "    filetest = open(\"test3.dat\", \"w+\")\n",
    "   \n",
    "   @sync begin\n",
    "\n",
    "   @async for i=1:32\n",
    "        @threads for j=1:55\n",
    "           write(filetest,\"$i $j \\n\")\n",
    "       end\n",
    "   end\n",
    "end\n",
    "\n",
    "close(filetest)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @benchmark not defined\nin expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @benchmark not defined\n",
      "in expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1\n"
     ]
    }
   ],
   "source": [
    "t4 = @benchmark begin\n",
    "    filetest = open(\"test4.dat\", \"w+\")\n",
    "   \n",
    "   @sync begin\n",
    "\n",
    "   @async for i=1:32\n",
    "        for j=1:55\n",
    "        @spawn write(filetest,\"$i $j \\n\")\n",
    "       end\n",
    "   end\n",
    "end\n",
    "\n",
    "close(filetest)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope. Writing shouldn't be parallelised. This isn't advantageous. Atom moves on the otherhand benefit from this. Operations, and in particular for-loops for the storage steps are next on the agenda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing some Runner functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @spawn not defined\nin expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:15",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @spawn not defined\n",
      "in expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:15\n"
     ]
    }
   ],
   "source": [
    "function test_things(x,mc_states)\n",
    "    file = RuNNer.writeinit(pwd())\n",
    "    if x == true\n",
    "        @sync begin\n",
    "        @threads for mc_state in mc_states\n",
    "            writeconfig(file,mc_state.config,\"Cu\")\n",
    "        end\n",
    "        end\n",
    "    elseif x == false\n",
    "        for mc_state in mc_states\n",
    "            writeconfig(file,mc_state.config,\"Cu\")\n",
    "        end\n",
    "    elseif x == 1\n",
    "        for mc_state in mc_states\n",
    "           @spawn writeconfig(file,mc_state.config,\"Cu\")\n",
    "        end\n",
    "    end\n",
    "    close(file)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @benchmark not defined\nin expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @benchmark not defined\n",
      "in expression starting at /home/grayseff/Code/ParallelTemperingMonteCarlo.jl/scripts/parallelisenotebook.ipynb:1\n"
     ]
    }
   ],
   "source": [
    "@benchmark test_things(true,mc_states)\n",
    "\n",
    "@benchmark test_things(1,mc_states)\n",
    "\n",
    "@benchmark test_things(false,mc_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, significantly faster to not thread the writing step, what we can try is writing several files. Next the pmap formalism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    " @everywhere curry(f,y1,y2,y3,y4,y5,y6,y7,y8) = x -> f(x,y1,y2,y3,y4,y5,y6,y7,y8)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
