{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{Int64}:\n",
       " 18\n",
       " 19\n",
       " 20\n",
       " 21\n",
       " 22\n",
       " 23\n",
       " 24\n",
       " 25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Distributed\n",
    "using Base.Threads\n",
    "@everywhere begin\n",
    "    using BenchmarkTools\n",
    "    using ParallelTemperingMonteCarlo\n",
    "end\n",
    "#addprocs(nthreads())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use a function of several variables in the pmap environment we require a curry function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere curry(f,y) = x -> f(x,y)\n",
    "@everywhere add_xy(x,y) = x + y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Int64}:\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pmap(curry(add_xy,10), 1:5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB spawning processes is expensive and _not recommended at all_ for simple loops and functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync macros\n",
    "\n",
    "sync requires all tasks inside to complete before moving on, async moves right on along without waiting, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slept for two\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nice and rested\n"
     ]
    }
   ],
   "source": [
    "@sync begin\n",
    "    sleep(2)\n",
    "    println(\"slept for two\")\n",
    "\n",
    "    @async begin \n",
    "        sleep(5)\n",
    "        println(\"nice and rested\")\n",
    "    end\n",
    "#the async wrapper skips straight to done\n",
    "    println(\"done\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll simulate a complex process with a 2 second sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simtest (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function simtest(x)\n",
    "    sleep(2)\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      " 20.016610 seconds (1.16 k allocations: 35.969 KiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  2.024840 seconds (2.64 k allocations: 133.564 KiB, 1.09% compilation time)\n"
     ]
    }
   ],
   "source": [
    "@time begin \n",
    "    veccy = []\n",
    "    for i = 1:10\n",
    "\n",
    "        y = simtest(i)\n",
    "        push!(veccy,y)\n",
    "        \n",
    "    end\n",
    "    println(veccy)\n",
    "end\n",
    "\n",
    "@time begin \n",
    "    @sync for i = 1:10\n",
    "        veccy = []\n",
    "        @async begin \n",
    "            y = simtest(i)\n",
    "            push!(veccy,y)\n",
    "        end\n",
    "    end\n",
    "    println(veccy)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Asynchronous tasks are not parallel, demonstrated above they do boost performance for large operations. Use @spawn not @async for parallel operations\n",
    "\n",
    "Let's test a data unsafe operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "printtest (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function printtest(x::Bool = true)\n",
    "    println(\"begin\")\n",
    "    if x == true\n",
    "        @sync for i=1:10\n",
    "            @spawn println(\"$i $i $i $i $i \")\n",
    "        end\n",
    "    else\n",
    "        for i=1:10\n",
    "            println(\"$i $i $i $i $i \")\n",
    "        end\n",
    "    end\n",
    "    println(\"end\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "      From worker 3:\t6 6 6 6 6 \n",
      "      From worker 4:\t7 7 7 7 7 \n",
      "      From worker 2:\t5 5 5 5 5 \n",
      "      From worker 5:\t8 8 8 8 8 \n",
      "      From worker 7:\t10 10 10 10 10 \n",
      "      From worker 6:\t9 9 9 9 9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 22:\t1 1 1 1 1 \n",
      "      From worker 24:\t3 3 3 3 3 \n",
      "      From worker 23:\t2 2 2 2 2 \n",
      "      From worker 25:\t4 4 4 4 4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n",
      "  3.457296 seconds (2.62 k allocations: 123.656 KiB)\n",
      "done\n",
      "begin\n",
      "1 1 1 1 1 \n",
      "2 2 2 2 2 \n",
      "3 3 3 3 3 \n",
      "4 4 4 4 4 \n",
      "5 5 5 5 5 \n",
      "6 6 6 6 6 \n",
      "7 7 7 7 7 \n",
      "8 8 8 8 8 \n",
      "9 9 9 9 9 \n",
      "10 10 10 10 10 \n",
      "end\n",
      "  0.000178 seconds (517 allocations: 17.969 KiB)\n",
      "done\n",
      "begin\n",
      "7 7 7 7 7 \n",
      "1 1 1 1 1 \n",
      "2 2 2 2 2 \n",
      "10 10 10 10 10 \n",
      "3 3 3 3 3 \n",
      "4 4 4 4 4 \n",
      "5 5 5 5 5 \n",
      "8 8 8 8 8 \n",
      "6 6 6 6 6 \n",
      "9 9 9 9 9 \n",
      "end\n",
      "  0.023980 seconds (18.15 k allocations: 1.024 MiB, 96.25% compilation time)\n"
     ]
    }
   ],
   "source": [
    "@time printtest()\n",
    "println(\"done\")\n",
    "@time printtest(false)\n",
    "println(\"done\")\n",
    "@time begin \n",
    "    println(\"begin\")\n",
    "    @threads for i=1:10\n",
    "        println(\"$i $i $i $i $i \")\n",
    "    end\n",
    "    println(\"end\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB \n",
    "Categorically do not use @spawn where data ordering is relevant. Additionally, it is considered bad practice to parallelise any operation faster than 100 $\\mu m$ for threads or 100ms for spawning as it does not increase speed enough to compensate for the time taken to spawn the operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
